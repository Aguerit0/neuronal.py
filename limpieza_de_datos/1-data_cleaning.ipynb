{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de Datos**\n",
    "\n",
    "La limpieza de datos es un paso fundamental en el proceso de análisis de datos que implica identificar y corregir errores, inconsistencias y datos incompletos en conjuntos de datos. Este proceso es crucial para garantizar la precisión y la fiabilidad de los resultados analíticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos de Limpieza de Datos**\n",
    "\n",
    "1) Identificación de Datos Incorrectos o Faltantes:\n",
    "\n",
    "    -   Revisar el conjunto de datos en busca de valores atípicos, valores nulos o valores que no tienen sentido.\n",
    "    -   Identificar patrones y tendencias en los datos para comprender mejor la naturaleza de los errores.\n",
    "\n",
    "2) Tratamiento de Valores Atípicos:\n",
    "\n",
    "    -   Evaluar si los valores atípicos son errores de entrada o representan información relevante.\n",
    "    -   Decidir si eliminar, corregir o mantener los valores atípicos según el contexto del análisis.\n",
    "\n",
    "3) Manejo de Valores Nulos:\n",
    "\n",
    "    -   Determinar si los valores nulos son resultado de errores o si indican información ausente.\n",
    "    -   Estrategias comunes incluyen eliminar filas con valores nulos, imputar valores basados en estadísticas, o utilizar técnicas más avanzadas como modelos de imputación.\n",
    "\n",
    "4) Normalización y Estandarización:\n",
    "\n",
    "    -   Asegurarse de que los datos estén en un formato consistente y comparable.\n",
    "    -   Normalizar datos categóricos, estandarizar unidades de medida y escalar características numéricas para evitar sesgos en el análisis.\n",
    "\n",
    "5) Consolidación de Datos Duplicados:\n",
    "\n",
    "    -   Identificar y eliminar duplicados en el conjunto de datos para evitar redundancias y mejorar la eficiencia del análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.././csv/Customer_Call_List.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#   Importamos nuestro dataset (se encuentra el repositorio de GitHub)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.././csv/Customer_Call_List.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df\n\u001b[0;32m      4\u001b[0m df_copy \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[1;32md:\\Descargas\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32md:\\Descargas\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1497\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1498\u001b[0m     )\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1503\u001b[0m         )\n",
      "File \u001b[1;32md:\\Descargas\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1372\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Descargas\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.././csv/Customer_Call_List.xlsx'"
     ]
    }
   ],
   "source": [
    "#   Importamos nuestro dataset (se encuentra el repositorio de GitHub)\n",
    "df = pd.read_excel('.././csv/Customer_Call_List.xlsx')\n",
    "df\n",
    "df_copy = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seleccionar columnas que nos interesan**\n",
    "\n",
    "-   .drop(): elimina una columna RECIBE POR PARÁMETRO CUAL COLUMNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Eliminamos columna innecesaria\n",
    "\n",
    "df.drop(columns='Not_Useful_Column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Eliminamos del df definitivamente\n",
    "\n",
    "df = df.drop(columns='Not_Useful_Column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identificar y eliminar duplicados** \n",
    "\n",
    " -  Para evitar redundancias y mejorar la eficiencia del análisis.**\n",
    " -  .drop_duplicates(): eliminar columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos columnas duplicadas\n",
    "\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos definitivamente columnas duplicadas\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Búsqueda de valores atípicos, valores nulos o valores que no tienen sentido.**\n",
    "\n",
    "Funciones:\n",
    "-   str(): Convierte el objeto en una representación de cadena.\n",
    "-   strip(): Elimina los espacios en blanco al principio y al final de una cadena.\n",
    "-   lstrip(): Elimina los espacios en blanco solo del lado izquierdo de una cadena.\n",
    "-   fillna(): Rellena los valores nulos (NaN) con un valor específico.\n",
    "-   dropna(): Elimina filas o columnas que contienen valores nulos.\n",
    "-   isdigit(): Devuelve True si todos los caracteres de una cadena son dígitos, False de lo contrario.\n",
    "-   isnull(): Devuelve True si el valor es nulo (NaN), False de lo contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Mostramos DF\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   carácteres atípicos: / ... _ |\n",
    "-   valores nulos: NaN N/a nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Trabajamos con la columna Last_Name\n",
    "\n",
    "df['Last_Name'].str.lstrip('.')\n",
    "df['Last_Name'].str.strip('/._')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Modificamos el df\n",
    "\n",
    "df['Last_Name'] = df['Last_Name'].str.strip('/._')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Mostramos columna Phone_Number\n",
    "\n",
    "df['Phone_Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Función para limpiar datos numericos de 'Phone_Number'\n",
    "#   join(): unir digitos filtrados en una única cadena\n",
    "#   isdigit: filtrar digitos de una cadena str\n",
    "\n",
    "def clean_phone_number(phone):\n",
    "    if pd.isnull(phone): return None\n",
    "    else: return ''.join(filter(str.isdigit, str(phone)))\n",
    "\n",
    "df['Phone_Number'] = df['Phone_Number'].apply(clean_phone_number)\n",
    "df['Phone_Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Aplicamos lambda para modificar a string la columna Number\n",
    "\n",
    "df['Phone_Number'] = df['Phone_Number'].apply(lambda x: str(x))\n",
    "df['Phone_Number']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Reemplazamos datos innecesarios\n",
    "\n",
    "df['Phone_Number'] = df['Phone_Number'].str.replace('None', '')\n",
    "df['Phone_Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subdivisión de columnas**\n",
    "\n",
    "-   Separar datos contenidos en una misma columna, por ejemplo datos geograficos o fechas\n",
    "-   Nos sirve para analizar de manera mas puntual un dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Mostramos DF\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Seleccionamos columna\n",
    "\n",
    "df[['Street', 'City', 'Number']] = df['Address'].str.split(',',n=2, expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIFICAR DATOS IGUALES CON DIFERENTE NOMBRE**\n",
    "\n",
    "-   Por ejemplo: 1=uno, True=['Verdadero', 'V']\n",
    "-   .replace(): reemplazar un dato por otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Podemos seleccionar todas las columnas del dataFramecon un bucle\n",
    "\n",
    "import numpy as np\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].replace('No','N')\n",
    "    df[column] = df[column].replace('Yes','Y')\n",
    "    df[column] = df[column].replace('N/a','')\n",
    "    df[column] = df[column].replace(np.nan,'-')\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparamos con el DF original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSIÓN**\n",
    "\n",
    "*La limpieza de datos fue esencial para asegurar la calidad y consistencia de los datos. Se aplicaron técnicas como la eliminación de valores nulos y la estandarización de formatos, lo que resultó en un conjunto de datos más confiable y apto para el análisis. Este proceso mejora la eficacia y precisión de cualquier modelo o análisis posterior. La limpieza de datos es un paso crucial en cualquier proyecto de análisis o modelado de datos para garantizar la fiabilidad y validez de los resultados.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
